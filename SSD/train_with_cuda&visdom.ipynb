{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "viz = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "gamma = 0.1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "if not os.path.exists('weights/'):\n",
    "    os.mkdir(args.save_folder)\n",
    "\n",
    "def train():\n",
    "    if not os.path.exists(COCO_ROOT):\n",
    "        print(\"Error: NO COCO_ROOT\")\n",
    "    cfg = coco\n",
    "    dataset = COCODetection(root=COCO_ROOT,\n",
    "                            transform=SSDAugmentation(cfg['min_dim'],\n",
    "                                                          MEANS))\n",
    "    \n",
    "    ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])\n",
    "\n",
    "    net = torch.nn.DataParallel(ssd_net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    vgg_weights = torch.load('weights/' + 'vgg16_reducedfc.pth')\n",
    "    print('Loading base network...')\n",
    "    ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "    \n",
    "    net = net.cuda()\n",
    "    \n",
    "    print('Initializing weights...')\n",
    "    # initialize newly added layers' weights with xavier method\n",
    "    ssd_net.extras.apply(weights_init)\n",
    "    ssd_net.loc.apply(weights_init)\n",
    "    ssd_net.conf.apply(weights_init)\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum,\n",
    "                          weight_decay=weight_decay)\n",
    "    criterion = MultiBoxLoss(cfg['num_classes'], 0.5, True, 0, True, 3, 0.5,\n",
    "                             False, True)\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    # loss counters\n",
    "    loc_loss = 0\n",
    "    conf_loss = 0\n",
    "    epoch = 0\n",
    "    print('Loading the dataset...')\n",
    "    \n",
    "    epoch_size = len(dataset) // 32\n",
    "    print('Training SSD on:', dataset.name)\n",
    "    \n",
    "    step_index = 0\n",
    "    \n",
    "    vis_title = 'SSD.PyTorch on ' + dataset.name\n",
    "    vis_legend = ['Loc Loss', 'Conf Loss', 'Total Loss']\n",
    "    iter_plot = create_vis_plot('Iteration', 'Loss', vis_title, vis_legend)\n",
    "    epoch_plot = create_vis_plot('Epoch', 'Loss', vis_title, vis_legend)\n",
    "    \n",
    "    data_loader = data.DataLoader(dataset, 32,\n",
    "                                  num_workers=4,\n",
    "                                  shuffle=True, collate_fn=detection_collate,\n",
    "                                  pin_memory=True)\n",
    "    \n",
    "    # create batch iterator\n",
    "    batch_iterator = iter(data_loader)\n",
    "    for iteration in range(0, cfg['max_iter']):\n",
    "        if iteration != 0 and (iteration % epoch_size == 0):\n",
    "            update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, None,\n",
    "                            'append', epoch_size)\n",
    "            \n",
    "            # reset epoch loss counters\n",
    "            loc_loss = 0\n",
    "            conf_loss = 0\n",
    "            epoch += 1\n",
    "            \n",
    "        if iteration in cfg['lr_steps']:\n",
    "            step_index += 1\n",
    "            adjust_learning_rate(optimizer, gamma, step_index)\n",
    "            \n",
    "        # load train data\n",
    "        images, targets = next(batch_iterator)\n",
    "        images = Variable(images.cuda())\n",
    "        targets = [Variable(ann.cuda(), volatile=True) for ann in targets]\n",
    "        \n",
    "        # forward\n",
    "        t0 = time.time()\n",
    "        out = net(images)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss_l, loss_c = criterion(out, targets)\n",
    "        loss = loss_l + loss_c\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time.time()\n",
    "        loc_loss += loss_l.data\n",
    "        conf_loss += loss_c.data\n",
    "        \n",
    "        if iteration % 10 == 0:\n",
    "            print('timer: %.4f sec.' % (t1 - t0))\n",
    "            print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.data), end=' ')\n",
    "            \n",
    "        update_vis_plot(iteration, loss_l.data, loss_c.data,\n",
    "                            iter_plot, epoch_plot, 'append')\n",
    "        \n",
    "        if iteration != 0 and iteration % 5000 == 0:\n",
    "            print('Saving state, iter:', iteration)\n",
    "            torch.save(ssd_net.state_dict(), 'weights/ssd512_COCO_' +\n",
    "                       repr(iteration) + '.pth')\n",
    "    torch.save(ssd_net.state_dict(),\n",
    "               'weights/' + '' + 'COCO' + '.pth')\n",
    "    \n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
    "        specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def xavier(param):\n",
    "    init.xavier_uniform(param)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "def create_vis_plot(_xlabel, _ylabel, _title, _legend):\n",
    "    return viz.line(\n",
    "        X=torch.zeros((1,)).cpu(),\n",
    "        Y=torch.zeros((1, 3)).cpu(),\n",
    "        opts=dict(\n",
    "            xlabel=_xlabel,\n",
    "            ylabel=_ylabel,\n",
    "            title=_title,\n",
    "            legend=_legend\n",
    "        )\n",
    "    )\n",
    "\n",
    "def update_vis_plot(iteration, loc, conf, window1, window2, update_type,\n",
    "                    epoch_size=1):\n",
    "    viz.line(\n",
    "        X=torch.ones((1, 3)).cpu() * iteration,\n",
    "        Y=torch.Tensor([loc, conf, loc + conf]).unsqueeze(0).cpu() / epoch_size,\n",
    "        win=window1,\n",
    "        update=update_type\n",
    "    )\n",
    "    \n",
    "    # initialize epoch plot on first iteration\n",
    "    if iteration == 0:\n",
    "        viz.line(\n",
    "            X=torch.zeros((1, 3)).cpu(),\n",
    "            Y=torch.Tensor([loc, conf, loc + conf]).unsqueeze(0).cpu(),\n",
    "            win=window2,\n",
    "            update=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
